{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework exercise 4\n",
    "## Deadline: upload to Moodle by 22 June 18:00 h\n",
    "\n",
    "__Please submit your homework either as a Jupyter Notebook or using .py files.__\n",
    "\n",
    "If you use .py files, please also include a PDF containing the output of your code and your explanations. Either way, the code needs to be in a form that can be easily run on another computer.\n",
    "\n",
    "__Name 1:__\n",
    "\n",
    "__Name 2:__\n",
    "\n",
    "__Name 3:__\n",
    "\n",
    "\n",
    "The name of the file that you upload should be named *Homework1_YourLastName_YourStudentID*.\n",
    "\n",
    "Reminder: you are required to attend class on 23 June to earn points for this homework exercise unless you have a valid reason for your absence.\n",
    "\n",
    "You are encouraged to work on this exercise in teams of up to three students. If any part of the questions is unclear, please ask on the Moodle forum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification, Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Classification__\n",
    "\n",
    "Attached you will find a file `company_data.csv` that contains data for a list of US-listed stocks for the year 2019. Each row contains data for one company, and the columns contain the following features: total assets, number of shares outstanding, long-term debt, EBIT, EBITDA, net income, stock price at the end of the year, highest price of the year, lowest price of the year, and the exchange code indicating on which exchange a stock is listed, where the value 11 refers to the New York Stock Exchange and the value 14 to Nasdaq. Before proceeding with the classification task, remove all rows where (i) any column has a missing value, (ii) the exchange code is different from 11 or 14, (iii) any duplicates.\n",
    "\n",
    "Please use the data to predict the exchange listing using\n",
    "\n",
    "* a Perceptron\n",
    "* a DecisionTreeClassifier\n",
    "\n",
    "You may increase the number of features by combining columns contained in the data set (e.g., earnings per share, to give just one example) before applying the learning algorithms.\n",
    "\n",
    "Split the data into training and test data and apply the learning algorithms for various choices of the hyperparameters. (You are not expected to systematically find the best hyperparmeters, but please include all choices that you tried in your homework submission and not just the one delivering the best results.) For each choice of hyperparameters, report the percentage of correctly classified stocks for the training data and for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv(\"company_data.csv\")\n",
    "text = pd.read_csv(\"text_data.csv\")\n",
    "company.dropna(inplace=True)\n",
    "company.drop(company[(company.exchg != 11) & (company.exchg != 14)].index, inplace=True)\n",
    "company.drop_duplicates(inplace=True)\n",
    "y = company.pop(\"exchg\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(company.values, y.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Sentiment Analysis__\n",
    "\n",
    "Attached you will find a file `text_data.csv` that contains a list of sentences related to finance. For each sentence, i.e., for each row in the table, the data contains an indicator for sentiment: negative, positive, or neutral.\n",
    "\n",
    "Please use the data to create a bag-of-words model using only unigrams. Split the data into training and test data and use a DecisionTreeClassifier to predict the sentiment.\n",
    "\n",
    "As in the previous questions, train the model for various choices of hyperparameters and report the results for training and test data for each choice.\n",
    "\n",
    "Repeat the task except that you now use both unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e",
   "display_name": "Python 3.7.4  ('Finance': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}