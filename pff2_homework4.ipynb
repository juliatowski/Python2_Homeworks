{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework exercise 4\n",
    "## Deadline: upload to Moodle by 22 June 18:00 h\n",
    "\n",
    "__Please submit your homework either as a Jupyter Notebook or using .py files.__\n",
    "\n",
    "If you use .py files, please also include a PDF containing the output of your code and your explanations. Either way, the code needs to be in a form that can be easily run on another computer.\n",
    "\n",
    "__Name 1:__\n",
    "\n",
    "__Name 2:__\n",
    "\n",
    "__Name 3:__\n",
    "\n",
    "\n",
    "The name of the file that you upload should be named *Homework1_YourLastName_YourStudentID*.\n",
    "\n",
    "Reminder: you are required to attend class on 23 June to earn points for this homework exercise unless you have a valid reason for your absence.\n",
    "\n",
    "You are encouraged to work on this exercise in teams of up to three students. If any part of the questions is unclear, please ask on the Moodle forum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification, Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Classification__\n",
    "\n",
    "Attached you will find a file `company_data.csv` that contains data for a list of US-listed stocks for the year 2019. Each row contains data for one company, and the columns contain the following features: total assets, number of shares outstanding, long-term debt, EBIT, EBITDA, net income, stock price at the end of the year, highest price of the year, lowest price of the year, and the exchange code indicating on which exchange a stock is listed, where the value 11 refers to the New York Stock Exchange and the value 14 to Nasdaq. Before proceeding with the classification task, remove all rows where (i) any column has a missing value, (ii) the exchange code is different from 11 or 14, (iii) any duplicates.\n",
    "\n",
    "Please use the data to predict the exchange listing using\n",
    "\n",
    "* a Perceptron\n",
    "* a DecisionTreeClassifier\n",
    "\n",
    "You may increase the number of features by combining columns contained in the data set (e.g., earnings per share, to give just one example) before applying the learning algorithms.\n",
    "\n",
    "Split the data into training and test data and apply the learning algorithms for various choices of the hyperparameters. (You are not expected to systematically find the best hyperparmeters, but please include all choices that you tried in your homework submission and not just the one delivering the best results.) For each choice of hyperparameters, report the percentage of correctly classified stocks for the training data and for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             at     csho       dltt      ebit    ebitda        ni  prcc_c  \\\n",
       "0      2079.000   35.097    670.900   108.400   152.100     4.400   45.10   \n",
       "1     59995.000  428.203  28875.000  3706.000  6024.000  1686.000   28.68   \n",
       "2       408.637   35.137     81.457    19.622    30.231    17.707    7.66   \n",
       "3       286.612   19.290      0.000    -1.173    -1.173    91.431   13.63   \n",
       "4     18479.247  112.436   4884.430   671.960  1262.889   538.320   89.93   \n",
       "...         ...      ...        ...       ...       ...       ...     ...   \n",
       "5333    519.067   18.764    178.194    -7.886    40.877   -43.487    6.49   \n",
       "5334    460.302   34.603    198.925    27.193    55.840     7.507    2.15   \n",
       "5335   2302.500   48.300    117.100   154.900   240.700   113.300   44.55   \n",
       "5336     30.421    3.318     14.234     1.284     1.840     1.088    1.85   \n",
       "5337     65.955   10.745      0.520   -26.332   -26.282   -34.933    9.70   \n",
       "\n",
       "       prch_c   prcl_c  exchg  \n",
       "0     52.7800  29.8400     11  \n",
       "1     37.2300  24.2300     14  \n",
       "2      9.8400   6.5000     14  \n",
       "3     13.8000   9.0300     11  \n",
       "4     99.8100  81.6300     11  \n",
       "...       ...      ...    ...  \n",
       "5333   7.9700   4.6700     14  \n",
       "5334   4.3000   1.5600     14  \n",
       "5335  46.3300  26.5694     11  \n",
       "5336  18.9989   1.8000     14  \n",
       "5337  28.9900   6.2000     14  \n",
       "\n",
       "[4299 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>at</th>\n      <th>csho</th>\n      <th>dltt</th>\n      <th>ebit</th>\n      <th>ebitda</th>\n      <th>ni</th>\n      <th>prcc_c</th>\n      <th>prch_c</th>\n      <th>prcl_c</th>\n      <th>exchg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2079.000</td>\n      <td>35.097</td>\n      <td>670.900</td>\n      <td>108.400</td>\n      <td>152.100</td>\n      <td>4.400</td>\n      <td>45.10</td>\n      <td>52.7800</td>\n      <td>29.8400</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>59995.000</td>\n      <td>428.203</td>\n      <td>28875.000</td>\n      <td>3706.000</td>\n      <td>6024.000</td>\n      <td>1686.000</td>\n      <td>28.68</td>\n      <td>37.2300</td>\n      <td>24.2300</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408.637</td>\n      <td>35.137</td>\n      <td>81.457</td>\n      <td>19.622</td>\n      <td>30.231</td>\n      <td>17.707</td>\n      <td>7.66</td>\n      <td>9.8400</td>\n      <td>6.5000</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>286.612</td>\n      <td>19.290</td>\n      <td>0.000</td>\n      <td>-1.173</td>\n      <td>-1.173</td>\n      <td>91.431</td>\n      <td>13.63</td>\n      <td>13.8000</td>\n      <td>9.0300</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18479.247</td>\n      <td>112.436</td>\n      <td>4884.430</td>\n      <td>671.960</td>\n      <td>1262.889</td>\n      <td>538.320</td>\n      <td>89.93</td>\n      <td>99.8100</td>\n      <td>81.6300</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5333</th>\n      <td>519.067</td>\n      <td>18.764</td>\n      <td>178.194</td>\n      <td>-7.886</td>\n      <td>40.877</td>\n      <td>-43.487</td>\n      <td>6.49</td>\n      <td>7.9700</td>\n      <td>4.6700</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5334</th>\n      <td>460.302</td>\n      <td>34.603</td>\n      <td>198.925</td>\n      <td>27.193</td>\n      <td>55.840</td>\n      <td>7.507</td>\n      <td>2.15</td>\n      <td>4.3000</td>\n      <td>1.5600</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5335</th>\n      <td>2302.500</td>\n      <td>48.300</td>\n      <td>117.100</td>\n      <td>154.900</td>\n      <td>240.700</td>\n      <td>113.300</td>\n      <td>44.55</td>\n      <td>46.3300</td>\n      <td>26.5694</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5336</th>\n      <td>30.421</td>\n      <td>3.318</td>\n      <td>14.234</td>\n      <td>1.284</td>\n      <td>1.840</td>\n      <td>1.088</td>\n      <td>1.85</td>\n      <td>18.9989</td>\n      <td>1.8000</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5337</th>\n      <td>65.955</td>\n      <td>10.745</td>\n      <td>0.520</td>\n      <td>-26.332</td>\n      <td>-26.282</td>\n      <td>-34.933</td>\n      <td>9.70</td>\n      <td>28.9900</td>\n      <td>6.2000</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n<p>4299 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "company = pd.read_csv(\"company_data.csv\")\n",
    "text = pd.read_csv(\"text_data.csv\")\n",
    "company.dropna(inplace=True)\n",
    "company.drop_duplicates(inplace=True)\n",
    "company.drop(company[(company.exchg != 11) & (company.exchg != 14)].index, inplace=True)\n",
    "company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Sentiment Analysis__\n",
    "\n",
    "Attached you will find a file `text_data.csv` that contains a list of sentences related to finance. For each sentence, i.e., for each row in the table, the data contains an indicator for sentiment: negative, positive, or neutral.\n",
    "\n",
    "Please use the data to create a bag-of-words model using only unigrams. Split the data into training and test data and use a DecisionTreeClassifier to predict the sentiment.\n",
    "\n",
    "As in the previous questions, train the model for various choices of hyperparameters and report the results for training and test data for each choice.\n",
    "\n",
    "Repeat the task except that you now use both unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e",
   "display_name": "Python 3.7.4 64-bit ('Finance': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "metadata": {
   "interpreter": {
    "hash": "d3adbaf49ae7f507e83f0ccfbb2546a5cc19668fb515a7486c42bc7952ccb80e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}